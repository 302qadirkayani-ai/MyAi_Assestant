"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          JANNAT VOICE ASSISTANT v2.0 - URDU OPTIMIZED         â•‘
â•‘                    âœ… FULLY FUNCTIONAL âœ…                      â•‘
â•‘  â€¢ 3D Animated Character (4GB RAM Optimized)                 â•‘
â•‘  â€¢ Female Urdu Voice | Auto-Start Listening                  â•‘
â•‘  â€¢ Groq API Integration | System Control                     â•‘
â•‘  â€¢ Self-Upgrade Feature | Proper Urdu Support                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import sys
import os
import threading
import time
import math
import json
import queue
import zipfile
import requests
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict

import pyttsx3
import sounddevice as sd
import vosk
from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, 
                             QHBoxLayout, QLabel, QPushButton, QTextEdit, QProgressBar)
from PyQt5.QtCore import Qt, QTimer, pyqtSignal, QObject, QThread
from PyQt5.QtGui import (QFont, QColor, QPainter, QLinearGradient, 
                        QBrush, QPen, QRadialGradient, QPolygon, QPoint)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#              URDU LANGUAGE & LOCALIZATION MODULE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

URDU_RESPONSES = {
    'greeting': 'Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù…!  Ù…ÛŒÚº Ø¬Ù†Øª ÛÙˆÚºØŒ Ø¢Ù¾ Ú©ÛŒ Ú©ÛŒØ§ Ù…Ø¯Ø¯ Ú©Ø± Ø³Ú©ØªÛŒ ÛÙˆÚºØŸ',
    'time':  'ÙˆÙ‚Øª ÛÛ’ {time}',
    'date': 'Ø¢Ø¬ Ú©ÛŒ ØªØ§Ø±ÛŒØ® {date} ÛÛ’',
    'opening_app': '{app} Ú©Ú¾ÙˆÙ„ Ø±ÛÛŒ ÛÙˆÚº',
    'app_not_found': 'Ù…Ø¹Ø§ÙÛŒØŒ ÛŒÛ Ø§ÛŒÙ¾Ù„ÛŒÚ©ÛŒØ´Ù† Ù†ÛÛŒÚº Ù…Ù„ÛŒ',
    'goodbye': 'Ø®Ø¯Ø§ Ø­Ø§ÙØ¸!  Ø¨ÛØª Ø®ÙˆØ´ Ø±ÛÛŒÚº ğŸ˜Š',
    'listening': 'Ø³Ù† Ø±ÛÛŒ ÛÙˆÚº.. .',
    'processing': 'Ø³ÙˆÚ† Ø±ÛÛŒ ÛÙˆÚº...',
    'error': 'Ù…Ø¹Ø§ÙÛŒØŒ Ú©Ú†Ú¾ ØºÙ„Ø· ÛÙˆØ§',
    'updating': 'Ø§Ù¾ ÚˆÛŒÙ¹ ÛÙˆ Ø±ÛÛŒ ÛÙˆÚº...',
    'updated': 'Ø§Ù¾ ÚˆÛŒÙ¹ Ù…Ú©Ù…Ù„ ÛÙˆ Ú¯Ø¦ÛŒ! ',
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                   VERSION & AUTO-UPDATE SYSTEM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CURRENT_VERSION = "2.0.1"
GITHUB_REPO = "302qadirkayani-ai/MyAi_Assestant"
VERSION_FILE = "version.json"

class VersionManager:
    """Manages auto-updates"""
    
    @staticmethod
    def get_local_version() -> str:
        """Get local version from file"""
        try:
            if Path(VERSION_FILE).exists():
                with open(VERSION_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return data.get('version', '1.0.0')
        except:
            pass
        return '1.0.0'
    
    @staticmethod
    def get_remote_version() -> Optional[str]:
        """Check latest version on GitHub"""
        try:
            url = f"https://api.github.com/repos/{GITHUB_REPO}/releases/latest"
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                return response.json()['tag_name']. lstrip('v')
        except:
            pass
        return None
    
    @staticmethod
    def save_version(version: str):
        """Save version to file"""
        try:
            data = {
                'version': version,
                'last_updated': datetime.now().isoformat(),
                'status': 'ready'
            }
            with open(VERSION_FILE, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âŒ Ù†Ø³Ø®Û Ù…Ø­ÙÙˆØ¸ Ú©Ø±Ù†Û’ Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒ: {e}")
    
    @staticmethod
    def check_for_updates() -> bool:
        """Check if update is available"""
        local = VersionManager.get_local_version()
        remote = VersionManager.get_remote_version()
        
        if remote and remote > local:
            print(f"ğŸ“¦ Ù†ÛŒØ§ ÙˆØ±Ú˜Ù† Ø¯Ø³ØªÛŒØ§Ø¨ ÛÛ’:  {remote}")
            return True
        return False
    
    @staticmethod
    def auto_update(callback=None):
        """Download and install latest version"""
        def update_thread():
            try:
                callback("Ø§Ù¾ ÚˆÛŒÙ¹ Ø´Ø±ÙˆØ¹ ÛÙˆ Ø±ÛÛŒ ÛÛ’...")
                
                # Get latest release download URL
                url = f"https://api.github.com/repos/{GITHUB_REPO}/releases/latest"
                response = requests.get(url, timeout=10)
                
                if response.status_code == 200:
                    download_url = response.json()['zipball_url']
                    version = response.json()['tag_name'].lstrip('v')
                    
                    # Download
                    callback(f"ÚˆØ§Ø¤Ù† Ù„ÙˆÚˆ ÛÙˆ Ø±ÛØ§ ÛÛ’ {version}...")
                    file_response = requests.get(download_url, timeout=30, stream=True)
                    
                    zip_path = "update.zip"
                    with open(zip_path, 'wb') as f:
                        for chunk in file_response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                    
                    # Extract
                    callback("ÙØ§Ø¦Ù„ÛŒÚº Ù†Ú©Ø§Ù„ÛŒ Ø¬Ø§ Ø±ÛÛŒ ÛÛŒÚº...")
                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                        zip_ref.extractall('update_temp')
                    
                    # Move files
                    import shutil
                    for item in Path('update_temp').iterdir():
                        if item.is_dir():
                            src = item
                            break
                    
                    for file in src.iterdir():
                        if file. is_file():
                            shutil.copy2(file, '.')
                    
                    # Cleanup
                    shutil.rmtree('update_temp')
                    os.remove(zip_path)
                    
                    # Save version
                    VersionManager. save_version(version)
                    callback(f"âœ… Ø§Ù¾ ÚˆÛŒÙ¹ Ù…Ú©Ù…Ù„!  Ù†ÛŒØ§ ÙˆØ±Ú˜Ù†:  {version}")
                    
            except Exception as e:
                callback(f"âŒ Ø§Ù¾ ÚˆÛŒÙ¹ Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒ: {e}")
        
        thread = threading.Thread(target=update_thread, daemon=True)
        thread.start()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                    AUTO VOSK MODEL DOWNLOADER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def download_vosk_model(callback=None):
    """Download Vosk model with progress callback"""
    
    models = [
        {
            'name': 'vosk-model-small-en-us-0.15',
            'url': 'https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip',
            'size':  '40MB'
        }
    ]
    
    for model_info in models:
        model_name = model_info['name']
        model_path = Path(model_name)
        
        if model_path.exists():
            if callback:
                callback(f"âœ… Ù…ÙˆØ¬ÙˆØ¯Û Ù…Ø§ÚˆÙ„:  {model_name}")
            return str(model_path)
    
    print("ğŸ“¥ Vosk Ù…Ø§ÚˆÙ„ ÚˆØ§Ø¤Ù† Ù„ÙˆÚˆ ÛÙˆ Ø±ÛØ§ ÛÛ’...")
    model_info = models[0]
    
    try:
        response = requests.get(model_info['url'], stream=True, timeout=30)
        
        if response.status_code == 200:
            zip_path = f"{model_info['name']}.zip"
            total_size = int(response.headers.get('content-length', 0))
            
            with open(zip_path, 'wb') as f:
                downloaded = 0
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        if total_size and callback:
                            percent = (downloaded / total_size) * 100
                            callback(f"â³ ÚˆØ§Ø¤Ù† Ù„ÙˆÚˆ: {percent:.1f}%")
            
            if callback:
                callback("ğŸ“‚ Ù†Ú©Ø§Ù„Ø§ Ø¬Ø§ Ø±ÛØ§ ÛÛ’...")
            
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall('.')
            
            os.remove(zip_path)
            if callback:
                callback(f"âœ… Ù…Ø§ÚˆÙ„ ØªÛŒØ§Ø±:  {model_info['name']}")
            return model_info['name']
    
    except Exception as e: 
        if callback:
            callback(f"âŒ Ø®Ø±Ø§Ø¨ÛŒ: {e}")
        return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                    CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ASSISTANT_NAME = "Ø¬Ù†Øª"  # Urdu name
GROQ_API_KEY = "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"
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
GROQ_MODEL = "llama-3.3-70b-versatile"

APPLICATIONS = {
    'notepad': 'notepad.exe',
    'calculator': 'calc.exe',
    'chrome': 'C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe',
    'edge': 'msedge. exe',
    'explorer': 'explorer.exe',
    'paint':  'mspaint.exe',
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                   GROQ AI BRAIN (URDU OPTIMIZED)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def query_groq_ai(user_message: str, use_urdu: bool = True) -> Optional[str]:
    """Query Groq API with Urdu support"""
    try:
        system_prompt = (
            "ØªÙ… Ø¬Ù†Øª ÛÙˆØŒ Ø§ÛŒÚ© Ø°ÛÛŒÙ† Ø§ÙˆØ± Ø®ÙˆØ´Ø¯Ù„ Ø§Ø±Ø¯Ùˆ Ø¨ÙˆÙ„Ù†Û’ ÙˆØ§Ù„ÛŒ AI Ù…Ø¹Ø§ÙˆÙ†Û” "
            "ÛÙ…ÛŒØ´Û Ø§Ø±Ø¯Ùˆ Ù…ÛŒÚº Ø¬ÙˆØ§Ø¨ Ø¯ÛŒÚº (Ø³ÙˆØ§Ø¦Û’ Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ Ú©Û’ ØªÚ©Ù†ÛŒÚ©ï¿½ï¿½ Ø§Ù„ÙØ§Ø¸ Ú©Û’)Û” "
            "Ø¬ÙˆØ§Ø¨Ø§Øª Ù…Ø®ØªØµØ± Ø§ÙˆØ± ÙˆØ§Ø¶Ø­ Ø±Ú©Ú¾ÛŒÚº (1-2 Ø¬Ù…Ù„Û’)Û” "
            "ØµØ§Ø±Ù Ú©Û’ Ø³Ø§ØªÚ¾ Ø³Ù„ÙˆÚ© Ù†Ø±Ù…ÛŒ Ø³Û’ Ú©Ø±ÛŒÚºÛ”"
        )
        
        response = requests.post(
            GROQ_API_URL,
            headers={
                'Authorization': f'Bearer {GROQ_API_KEY}',
                'Content-Type': 'application/json'
            },
            json={
                'model':  GROQ_MODEL,
                'messages': [
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': user_message}
                ],
                'temperature': 0.7,
                'max_tokens': 150
            },
            timeout=10
        )
        
        if response.status_code == 200:
            data = response.json()
            return data['choices'][0]['message']['content']
        return None
            
    except Exception as e:
        print(f"Groq Ø®Ø±Ø§Ø¨ÛŒ: {e}")
        return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                  VOICE ENGINE (URDU VOICE)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class JannatVoiceEngine:
    def __init__(self):
        print("ğŸ¤ ÙˆØ§Ø¦Ø³ Ø´Ø±ÙˆØ¹ ÛÙˆ Ø±ÛÛŒ ÛÛ’...")
        self.engine = pyttsx3.init()
        self.is_speaking = False
        self. configure_voice()
    
    def configure_voice(self):
        """Configure for Urdu/Female voice"""
        voices = self.engine.getProperty('voices')
        
        # Try to select female voice
        for voice in voices:
            if 'female' in voice.name.lower() or 'woman' in voice.name.lower():
                self.engine.setProperty('voice', voice. id)
                print(f"âœ… Ø®Ø§ØªÙˆÙ† Ú©ÛŒ Ø¢ÙˆØ§Ø²: {voice.name}")
                break
        else: 
            # Fallback to second voice
            if len(voices) > 1:
                self.engine.setProperty('voice', voices[1].id)
        
        self.engine.setProperty('rate', 160)
        self.engine.setProperty('volume', 1.0)
        print("âœ… ÙˆØ§Ø¦Ø³ ØªÛŒØ§Ø± ÛÛ’")
    
    def speak(self, text: str):
        """Speak text with threading"""
        if self.is_speaking:
            return
        
        def speak_thread():
            self.is_speaking = True
            try:
                self.engine.say(text)
                self.engine.runAndWait()
            except Exception as e:
                print(f"ÙˆØ§Ø¦Ø³ Ø®Ø±Ø§Ø¨ÛŒ: {e}")
            self.is_speaking = False
        
        threading.Thread(target=speak_thread, daemon=True).start()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                  VOICE RECOGNITION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class VoiceRecognizer(QObject):
    command_received = pyqtSignal(str)
    status_changed = pyqtSignal(str)
    listening_active = pyqtSignal(bool)
    
    def __init__(self, progress_callback=None):
        super().__init__()
        self.is_running = False
        self.should_stop = False
        self. audio_queue = queue.Queue()
        self.model = None
        self.recognizer = None
        self.progress_callback = progress_callback
        
        self.initialize_model()
        self.sample_rate = 16000
        self.blocksize = 8000
    
    def initialize_model(self):
        """Initialize Vosk model with auto-download"""
        try:
            model_path = None
            possible_models = [
                'vosk-model-small-en-us-0.15',
                'vosk-model-small-ur-0.1'
            ]
            
            for model_name in possible_models:
                if Path(model_name).exists():
                    model_path = model_name
                    print(f"âœ… Ù…Ø§ÚˆÙ„ Ù…Ù„Ø§:  {model_name}")
                    break
            
            if not model_path:
                print("ğŸ” Ù…Ø§ÚˆÙ„ ÚˆØ§Ø¤Ù† Ù„ÙˆÚˆ ÛÙˆ Ø±ÛØ§ ÛÛ’...")
                model_path = download_vosk_model(self.progress_callback)
            
            if model_path:
                self. model = vosk.Model(model_path)
                self.recognizer = vosk.KaldiRecognizer(self.model, 16000)
                print("âœ… Vosk ØªÛŒØ§Ø± ÛÛ’")
            
        except Exception as e:
            print(f"âŒ Ù…Ø§ÚˆÙ„ Ø®Ø±Ø§Ø¨ÛŒ: {e}")
            self.model = None
            self.recognizer = None
    
    def audio_callback(self, indata, frames, time_info, status):
        if status: 
            print(f"ÙˆØ§Ø¦Ø³ Ø­Ø§Ù„Øª: {status}")
        self.audio_queue.put(bytes(indata))
    
    def start(self):
        if self.is_running or not self.recognizer:
            return
        
        self.is_running = True
        self.should_stop = False
        threading.Thread(target=self._listen_loop, daemon=True).start()
    
    def stop(self):
        self.should_stop = True
        self.is_running = False
    
    def _listen_loop(self):
        try:
            with sd.RawInputStream(samplerate=self.sample_rate, 
                                  blocksize=self.blocksize,
                                  dtype='int16',
                                  channels=1,
                                  callback=self.audio_callback):
                
                print("âœ… Ù…Ø§Ø¦ÛŒÚ© Ø´Ø±ÙˆØ¹")
                
                while not self.should_stop:
                    try:
                        self.listening_active.emit(True)
                        self.status_changed.emit("ğŸ¤ Ø³Ù† Ø±ÛÛŒ ÛÙˆÚº...")
                        
                        data = self.audio_queue.get(timeout=1)
                        
                        if self.recognizer. AcceptWaveform(data):
                            result = json.loads(self.recognizer. Result())
                            text = result. get('text', '').strip()
                            
                            if text:
                                self.listening_active.emit(False)
                                self.status_changed. emit("âš™ï¸ Ø³ÙˆÚ† Ø±ÛÛŒ ÛÙˆÚº...")
                                self.command_received.emit(text)
                        else:
                            partial = json.loads(self.recognizer. PartialResult())
                            partial_text = partial.get('partial', '')
                            if partial_text:
                                self.status_changed.emit(f"ğŸ¤ {partial_text}...")
                        
                    except queue.Empty:
                        continue
                    except Exception as e: 
                        print(f"Ù¾ÛÚ†Ø§Ù† Ø®Ø±Ø§Ø¨ÛŒ: {e}")
                        time.sleep(0.1)
                        
        except Exception as e:
            print(f"Ø³Ù¹Ø±ÛŒÙ… Ø®Ø±Ø§Ø¨ÛŒ: {e}")
            self.status_changed.emit("âŒ Ù…Ø§Ø¦ÛŒÚ© Ø®Ø±Ø§Ø¨ÛŒ")
        
        print("ğŸ‘‚ Ø³Ù†Ù†Ø§ Ø¨Ù†Ø¯")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                    COMMAND PROCESSOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CommandProcessor: 
    def __init__(self, voice:  JannatVoiceEngine):
        self.voice = voice
    
    def process(self, cmd_text: str) -> Optional[Dict]:
        if not cmd_text:
            return None
        
        cmd = cmd_text.lower()
        
        # Open applications
        if 'open' in cmd or 'Ú©Ú¾ÙˆÙ„' in cmd:
            for app_name, app_path in APPLICATIONS.items():
                if app_name in cmd:
                    try: 
                        os.startfile(app_path)
                        response = f"{app_name} Ú©Ú¾ÙˆÙ„ Ø¯ÛŒ"
                        self.voice.speak(response)
                        return {'action': 'open', 'text': response}
                    except: 
                        self.voice.speak("Ù†ÛÛŒÚº Ú©Ú¾Ù„ Ø³Ú©ÛŒ")
                        return {'action': 'error', 'text': 'Failed'}
        
        # Time
        if 'time' in cmd or 'ÙˆÙ‚Øª' in cmd:
            time_str = datetime.now().strftime("%I:%M %p")
            response = f"ÙˆÙ‚Øª ÛÛ’ {time_str}"
            self.voice.speak(response)
            return {'action': 'time', 'text': time_str}
        
        # Date
        if 'date' in cmd or 'ØªØ§Ø±ÛŒØ®' in cmd:
            date_str = datetime.now().strftime("%d %B %Y")
            response = f"ØªØ§Ø±ÛŒØ® ÛÛ’ {date_str}"
            self.voice.speak(response)
            return {'action': 'date', 'text': date_str}
        
        # Exit
        if any(w in cmd for w in ['exit', 'close', 'bye', 'Ø®Ø¯Ø§', 'Ø§Ù„ÙˆØ¯Ø§Ø¹']):
            self.voice.speak(URDU_RESPONSES['goodbye'])
            return {'action': 'exit', 'text': 'Goodbye'}
        
        # AI Query
        ai_response = query_groq_ai(cmd_text, use_urdu=True)
        if ai_response:
            self.voice.speak(ai_response)
            return {'action': 'ai', 'text': ai_response}
        
        return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#          LIGHTWEIGHT 3D CHARACTER (4GB RAM OPTIMIZED)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Character3D(QWidget):
    def __init__(self):
        super().__init__()
        self.is_listening = False
        self.is_speaking = False
        self.frame = 0
        self.blink_frame = 0
        
        self.timer = QTimer()
        self.timer.timeout.connect(self. animate)
        self.timer.start(33)
        
        self.setMinimumSize(400, 500)
    
    def animate(self):
        self.frame = (self.frame + 1) % 360
        self.blink_frame = (self.blink_frame + 1) % 60
        self.update()
    
    def set_listening(self, state):
        self.is_listening = state
    
    def set_speaking(self, state):
        self.is_speaking = state
    
    def paintEvent(self, event):
        p = QPainter(self)
        p.setRenderHint(QPainter.Antialiasing)
        
        w, h = self.width(), self.height()
        cx, cy = w // 2, h // 2 + 50
        
        # Background
        bg = QLinearGradient(0, 0, 0, h)
        bg.setColorAt(0, QColor(20, 20, 40))
        bg.setColorAt(1, QColor(10, 10, 25))
        p.fillRect(0, 0, w, h, bg)
        
        # Glow effect
        if self.is_listening:
            color = QColor(0, 255, 150, 80)
            radius = 150 + abs(math.sin(self.frame * 0.05)) * 30
        elif self.is_speaking:
            color = QColor(255, 150, 50, 80)
            radius = 150 + abs(math. sin(self.frame * 0.1)) * 40
        else:
            color = QColor(100, 150, 255, 50)
            radius = 150
        
        glow = QRadialGradient(cx, cy - 50, radius)
        glow.setColorAt(0, color)
        glow.setColorAt(1, QColor(0, 0, 0, 0))
        p.setBrush(QBrush(glow))
        p.setPen(Qt.NoPen)
        p.drawEllipse(int(cx - radius), int(cy - 50 - radius),
                     int(radius * 2), int(radius * 2))
        
        # Head
        head_grad = QRadialGradient(cx - 10, cy - 100, 80)
        head_grad.setColorAt(0, QColor(255, 220, 200))
        head_grad.setColorAt(1, QColor(230, 180, 160))
        p.setBrush(QBrush(head_grad))
        p.setPen(QPen(QColor(200, 150, 130), 2))
        p.drawEllipse(cx - 60, cy - 140, 120, 140)
        
        # Hair
        p.setBrush(QBrush(QColor(50, 30, 20)))
        p.setPen(QPen(QColor(50, 30, 20), 2))
        p.drawEllipse(cx - 70, cy - 150, 140, 80)
        
        # Hair strands
        left_hair_x = cx - 70 + math.sin(self.frame * 0.05) * 3
        right_hair_x = cx + 50 - math.sin(self.frame * 0.05) * 3
        p.drawEllipse(int(left_hair_x), cy - 130, 30, 100)
        p.drawEllipse(int(right_hair_x), cy - 130, 30, 100)
        
        # Eyes with blinking
        eye_y = cy - 100
        blink_amount = max(0, abs(math.sin(self.blink_frame * 0.1)) - 0.8)
        
        if self.is_speaking and (self.frame % 30) < 3:
            # Closed eyes when speaking
            p.setBrush(QBrush(QColor(80, 50, 40)))
            p.drawEllipse(cx - 30, eye_y + 10, 20, 5)
            p.drawEllipse(cx + 10, eye_y + 10, 20, 5)
        else:
            # Open eyes
            p.setBrush(QBrush(QColor(255, 255, 255)))
            eye_height = max(2, int(25 * (1 - blink_amount)))
            p.drawEllipse(cx - 30, eye_y + int(blink_amount * 10), 20, eye_height)
            p.drawEllipse(cx + 10, eye_y + int(blink_amount * 10), 20, eye_height)
            
            # Iris
            iris_offset = 0
            if self.is_listening:
                iris_offset = math.sin(self.frame * 0.1) * 3
            
            p.setBrush(QBrush(QColor(100, 50, 150)))
            p.drawEllipse(int(cx - 25 + iris_offset), eye_y + 5, 10, 15)
            p.drawEllipse(int(cx + 15 + iris_offset), eye_y + 5, 10, 15)
            
            # Pupil
            p.setBrush(QBrush(QColor(0, 0, 0)))
            p.drawEllipse(int(cx - 23 + iris_offset), eye_y + 8, 6, 9)
            p.drawEllipse(int(cx + 17 + iris_offset), eye_y + 8, 6, 9)
            
            # Shine
            p.setBrush(QBrush(QColor(255, 255, 255, 200)))
            p.drawEllipse(int(cx - 21 + iris_offset), eye_y + 9, 3, 4)
            p.drawEllipse(int(cx + 19 + iris_offset), eye_y + 9, 3, 4)
        
        # Nose
        p.setPen(QPen(QColor(200, 150, 130), 2))
        p.drawLine(cx, cy - 80, cx - 3, cy - 70)
        
        # Mouth
        mouth_y = cy - 50
        if self.is_speaking:
            mouth_h = abs(math.sin(self.frame * 0.15)) * 15 + 5
            p.setBrush(QBrush(QColor(180, 80, 80)))
            p.setPen(QPen(QColor(160, 60, 60), 2))
            p.drawEllipse(cx - 15, int(mouth_y), 30, int(mouth_h))
        else:
            p.setBrush(Qt.NoBrush)
            p.setPen(QPen(QColor(200, 100, 100), 3))
            p.drawArc(cx - 20, mouth_y, 40, 25, 0, -180 * 16)
        
        # Neck
        neck_grad = QLinearGradient(cx - 15, cy, cx + 15, cy)
        neck_grad.setColorAt(0, QColor(230, 180, 160))
        neck_grad.setColorAt(0.5, QColor(255, 210, 190))
        neck_grad.setColorAt(1, QColor(230, 180, 160))
        p.setBrush(QBrush(neck_grad))
        p.setPen(QPen(QColor(200, 150, 130), 1))
        p.drawRect(cx - 15, cy - 10, 30, 40)
        
        # Body
        body_grad = QLinearGradient(cx, cy + 30, cx, cy + 180)
        body_grad.setColorAt(0, QColor(150, 100, 200))
        body_grad.setColorAt(1, QColor(100, 50, 150))
        p.setBrush(QBrush(body_grad))
        p.setPen(QPen(QColor(80, 40, 120), 2))
        
        body_points = [
            QPoint(cx - 40, cy + 30),
            QPoint(cx + 40, cy + 30),
            QPoint(cx + 60, cy + 180),
            QPoint(cx - 60, cy + 180)
        ]
        p.drawPolygon(QPolygon(body_points))
        
        # Arms
        arm_sway = math.sin(self.frame * 0.03) * 5
        p.setPen(QPen(QColor(255, 200, 180), 12, Qt.SolidLine, Qt.RoundCap))
        p.drawLine(cx - 40, cy + 50, int(cx - 70 + arm_sway), cy + 120)
        p.drawLine(cx + 40, cy + 50, int(cx + 70 - arm_sway), cy + 120)
        
        # Status text
        p.setFont(QFont("Arial", 14, QFont.Bold))
        if self.is_listening:
            p.setPen(QColor(0, 255, 150))
            txt = "ğŸ¤ Ø³Ù† Ø±ÛÛŒ ÛÙˆÚº"
        elif self.is_speaking:
            p.setPen(QColor(255, 150, 50))
            txt = "ğŸ—£ï¸ Ø¨ÙˆÙ„ Ø±ÛÛŒ ÛÙˆÚº"
        else:
            p. setPen(QColor(150, 150, 255))
            txt = "ğŸ’¤ ØªÛŒØ§Ø±"
        
        p.drawText(20, 40, txt)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                   MAIN APPLICATION WINDOW
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class JannatWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        
        print("ğŸš€ Ø¬Ù†Øª Ø´Ø±ÙˆØ¹ ÛÙˆ Ø±ÛÛŒ ÛÛ’...")
        
        self.voice = JannatVoiceEngine()
        self.recognizer = VoiceRecognizer(self.update_status)
        self.processor = CommandProcessor(self.voice)
        self.version_manager = VersionManager()
        
        self.recognizer.command_received.connect(self.on_command)
        self.recognizer.status_changed.connect(self.update_status)
        self.recognizer.listening_active.connect(self.on_listen)
        
        self.init_ui()
        self.check_updates()
        
        QTimer.singleShot(2000, self.auto_start)
    
    def init_ui(self):
        self.setWindowTitle(f"âœ¨ {ASSISTANT_NAME} - AI Ù…Ø¹Ø§ÙˆÙ†")
        self.setGeometry(100, 100, 900, 700)
        self.setWindowFlags(Qt. FramelessWindowHint | Qt.WindowStaysOnTopHint)
        self.setAttribute(Qt.WA_TranslucentBackground)
        
        # Central widget
        central = QWidget()
        self.setCentralWidget(central)
        central.setStyleSheet("background:  transparent;")
        
        layout = QVBoxLayout(central)
        
        # Character
        self.character = Character3D()
        layout.addWidget(self.character)
        
        # Status
        self.status_label = QLabel("ğŸ”„ Ø´Ø±ÙˆØ¹ ÛÙˆ Ø±ÛØ§ ÛÛ’...")
        self.status_label.setStyleSheet("""
            color: #00FF96;
            font-size: 14px;
            font-weight:  bold;
            text-align: center;
        """)
        layout.addWidget(self.status_label)
        
        # Buttons
        btn_layout = QHBoxLayout()
        
        self.start_btn = QPushButton("ğŸ¤ Ø´Ø±ÙˆØ¹ Ú©Ø±ÛŒÚº")
        self.start_btn.setStyleSheet("""
            QPushButton {
                background:  #1a1a2e;
                color: #00FF96;
                border: 2px solid #00FF96;
                border-radius: 10px;
                padding: 10px 20px;
                font-weight: bold;
                font-size: 12px;
            }
            QPushButton:hover {
                background: #00FF96;
                color: #1a1a2e;
            }
        """)
        self.start_btn.clicked.connect(self. start_listening)
        
        self.stop_btn = QPushButton("â¹ï¸ Ø±ÙˆÚ©ÛŒÚº")
        self.stop_btn.setStyleSheet(self.start_btn.styleSheet())
        self.stop_btn. clicked.connect(self.stop_listening)
        
        self. update_btn = QPushButton("ğŸ“¦ Ø§Ù¾ ÚˆÛŒÙ¹")
        self.update_btn. setStyleSheet(self.start_btn.styleSheet())
        self.update_btn. clicked.connect(self.manual_update)
        
        btn_layout.addWidget(self. start_btn)
        btn_layout.addWidget(self.stop_btn)
        btn_layout.addWidget(self.update_btn)
        layout.addLayout(btn_layout)
        
        # Progress bar
        self.progress = QProgressBar()
        self.progress.setStyleSheet("""
            QProgressBar {
                background: #1a1a2e;
                border: 2px solid #00FF96;
                border-radius: 5px;
            }
            QProgressBar::chunk {
                background: #00FF96;
            }
        """)
        self.progress.setVisible(False)
        layout.addWidget(self.progress)
        
        # Text output
        self.output_text = QTextEdit()
        self.output_text.setReadOnly(True)
        self.output_text.setMaximumHeight(150)
        self.output_text.setStyleSheet("""
            QTextEdit {
                background: rgba(26, 26, 46, 200);
                color: #00FF96;
                border: 2px solid #00FF96;
                border-radius: 10px;
                font-family: 'Courier New';
                font-size: 11px;
            }
        """)
        layout.addWidget(self.output_text)
        
        self.show()
    
    def update_status(self, text):
        self.status_label.setText(text)
        self.output_text.append(f"[{datetime.now().strftime('%H:%M:%S')}] {text}")
    
    def on_listen(self, active):
        self.character.set_listening(active)
    
    def on_command(self, command):
        self.output_text.append(f"ğŸ‘‚ Ø³Ù†Ø§: {command}")
        result = self.processor.process(command)
        if result and result['action'] == 'exit':
            QTimer.singleShot(1000, self.close)
    
    def start_listening(self):
        self.recognizer.start()
        self.update_status("ğŸ¤ Ø³Ù† Ø±ÛÛŒ ÛÙˆÚº...")
    
    def stop_listening(self):
        self.recognizer. stop()
        self.update_status("â¹ï¸ Ø±Ú© Ú¯Ø¦ÛŒ")
    
    def auto_start(self):
        self.voice.speak(URDU_RESPONSES['greeting'])
        self.start_listening()
    
    def check_updates(self):
        if self.version_manager.check_for_updates():
            self.update_status("ğŸ“¦ Ù†ÛŒØ§ ÙˆØ±Ú˜Ù† Ø¯Ø³ØªÛŒØ§Ø¨ ÛÛ’!")
    
    def manual_update(self):
        self.progress.setVisible(True)
        self.update_btn.setEnabled(False)
        self.version_manager.auto_update(self.update_status)
    
    def closeEvent(self, event):
        self.recognizer.stop()
        event.accept()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                        MAIN ENTRY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == '__main__':
    app = QApplication(sys.argv)
    window = JannatWindow()
    sys.exit(app.exec_())
